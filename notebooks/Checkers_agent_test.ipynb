{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xgDpm0Op6nRD"
   },
   "source": [
    "**Add gym-checkers to path**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "pwd = Path(os.getcwd())\n",
    "if (pwd.name == \"notebooks\"):\n",
    "    sys.path.append(str(pwd.parent / \"gym-checkers\"))\n",
    "else:\n",
    "    sys.path.append(str(pwd / \"gym-checkers\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g5JqySpj6cvd"
   },
   "source": [
    "**Quick test alpha-beta agent**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from checkers.game import Checkers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QzrYKxu35GpM",
    "outputId": "88359440-16bc-4a3a-c1ff-9113713f07b2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "game 0\n",
      "_b_b_b_b\n",
      "b_b_b_b_\n",
      "_b_b_b_b\n",
      "._._._._\n",
      "_._._._.\n",
      "w_w_w_w_\n",
      "_w_w_w_w\n",
      "w_w_w_w_\n",
      "0 turn: black last_moved_piece: None\n",
      "7 legal moves [(8, 12), (8, 13), (9, 13), (9, 14), (10, 14), (10, 15), (11, 15)]\n",
      "legal_move [(8, 12), (8, 13), (9, 13), (9, 14), (10, 14), (10, 15), (11, 15)]\n",
      "evaluated 30397 positions in 6.77s (avg 4491.25 positions/s) with effective branching factor 5.59\n",
      "best_move (8, 12)\n",
      "black moved 8, 12\n",
      "\n",
      "_b_b_b_b\n",
      "b_b_b_b_\n",
      "_._b_b_b\n",
      "b_._._._\n",
      "_._._._.\n",
      "w_w_w_w_\n",
      "_w_w_w_w\n",
      "w_w_w_w_\n",
      "1 turn: white last_moved_piece: None\n",
      "7 legal moves [(20, 16), (21, 17), (21, 16), (22, 18), (22, 17), (23, 19), (23, 18)]\n",
      "legal_move [(20, 16), (21, 17), (21, 16), (22, 18), (22, 17), (23, 19), (23, 18)]\n",
      "evaluated 1312 positions in 0.33s (avg 3940.53 positions/s) with effective branching factor 6.02\n",
      "best_move (23, 18)\n",
      "white moved 23, 18\n",
      "\n",
      "_b_b_b_b\n",
      "b_b_b_b_\n",
      "_._b_b_b\n",
      "b_._._._\n",
      "_._._w_.\n",
      "w_w_w_._\n",
      "_w_w_w_w\n",
      "w_w_w_w_\n",
      "2 turn: black last_moved_piece: None\n",
      "8 legal moves [(4, 8), (5, 8), (9, 13), (9, 14), (10, 14), (10, 15), (11, 15), (12, 16)]\n",
      "legal_move [(4, 8), (5, 8), (9, 13), (9, 14), (10, 14), (10, 15), (11, 15), (12, 16)]\n",
      "evaluated 15820 positions in 3.79s (avg 4171.29 positions/s) with effective branching factor 5.01\n",
      "best_move (9, 14)\n",
      "black moved 9, 14\n",
      "\n",
      "_b_b_b_b\n",
      "b_b_b_b_\n",
      "_._._b_b\n",
      "b_._b_._\n",
      "_._._w_.\n",
      "w_w_w_._\n",
      "_w_w_w_w\n",
      "w_w_w_w_\n",
      "3 turn: white last_moved_piece: None\n",
      "1 legal moves [(18, 9)]\n",
      "legal_move [(18, 9)]\n",
      "evaluated 0 positions in 0.00s (avg inf positions/s) with effective branching factor 0.00\n",
      "best_move (18, 9)\n",
      "white moved 18, 9\n",
      "\n",
      "_b_b_b_b\n",
      "b_b_b_b_\n",
      "_._w_b_b\n",
      "b_._._._\n",
      "_._._._.\n",
      "w_w_w_._\n",
      "_w_w_w_w\n",
      "w_w_w_w_\n",
      "4 turn: black last_moved_piece: None\n",
      "2 legal moves [(5, 14), (6, 13)]\n",
      "legal_move [(5, 14), (6, 13)]\n",
      "evaluated 12720 positions in 2.53s (avg 5023.22 positions/s) with effective branching factor 4.83\n",
      "best_move (6, 13)\n",
      "black moved 6, 13\n",
      "\n",
      "_b_b_b_b\n",
      "b_b_._b_\n",
      "_._._b_b\n",
      "b_b_._._\n",
      "_._._._.\n",
      "w_w_w_._\n",
      "_w_w_w_w\n",
      "w_w_w_w_\n",
      "5 turn: white last_moved_piece: None\n",
      "7 legal moves [(20, 16), (21, 17), (21, 16), (22, 18), (22, 17), (26, 23), (27, 23)]\n",
      "legal_move [(20, 16), (21, 17), (21, 16), (22, 18), (22, 17), (26, 23), (27, 23)]\n",
      "evaluated 1375 positions in 0.35s (avg 3930.34 positions/s) with effective branching factor 6.09\n",
      "best_move (21, 16)\n",
      "white moved 21, 16\n",
      "\n",
      "_b_b_b_b\n",
      "b_b_._b_\n",
      "_._._b_b\n",
      "b_b_._._\n",
      "_w_._._.\n",
      "w_._w_._\n",
      "_w_w_w_w\n",
      "w_w_w_w_\n",
      "6 turn: black last_moved_piece: None\n",
      "1 legal moves [(12, 21)]\n",
      "legal_move [(12, 21)]\n",
      "evaluated 0 positions in 0.00s (avg inf positions/s) with effective branching factor 0.00\n",
      "best_move (12, 21)\n",
      "black moved 12, 21\n",
      "\n",
      "_b_b_b_b\n",
      "b_b_._b_\n",
      "_._._b_b\n",
      "._b_._._\n",
      "_._._._.\n",
      "w_b_w_._\n",
      "_w_w_w_w\n",
      "w_w_w_w_\n",
      "7 turn: white last_moved_piece: None\n",
      "2 legal moves [(24, 17), (25, 16)]\n",
      "legal_move [(24, 17), (25, 16)]\n",
      "evaluated 24 positions in 0.01s (avg 3121.73 positions/s) with effective branching factor 2.21\n",
      "best_move (24, 17)\n",
      "white moved 24, 17\n",
      "\n",
      "_b_b_b_b\n",
      "b_b_._b_\n",
      "_._._b_b\n",
      "._b_._._\n",
      "_._w_._.\n",
      "w_._w_._\n",
      "_._w_w_w\n",
      "w_w_w_w_\n",
      "8 turn: white last_moved_piece: 17\n",
      "1 legal moves [(17, 8)]\n",
      "legal_move [(17, 8)]\n",
      "evaluated 0 positions in 0.00s (avg inf positions/s) with effective branching factor 0.00\n",
      "best_move (17, 8)\n",
      "white moved 17, 8\n",
      "\n",
      "_b_b_b_b\n",
      "b_b_._b_\n",
      "_w_._b_b\n",
      "._._._._\n",
      "_._._._.\n",
      "w_._w_._\n",
      "_._w_w_w\n",
      "w_w_w_w_\n",
      "9 turn: black last_moved_piece: None\n",
      "2 legal moves [(4, 13), (5, 12)]\n",
      "legal_move [(4, 13), (5, 12)]\n",
      "evaluated 47167 positions in 8.53s (avg 5527.62 positions/s) with effective branching factor 6.01\n",
      "best_move (4, 13)\n",
      "black moved 4, 13\n",
      "\n",
      "_b_b_b_b\n",
      "._b_._b_\n",
      "_._._b_b\n",
      "._b_._._\n",
      "_._._._.\n",
      "w_._w_._\n",
      "_._w_w_w\n",
      "w_w_w_w_\n",
      "10 turn: white last_moved_piece: None\n",
      "8 legal moves [(20, 16), (22, 18), (22, 17), (25, 21), (26, 23), (27, 23), (28, 24), (29, 24)]\n",
      "legal_move [(20, 16), (22, 18), (22, 17), (25, 21), (26, 23), (27, 23), (28, 24), (29, 24)]\n",
      "evaluated 3288 positions in 0.72s (avg 4586.79 positions/s) with effective branching factor 7.57\n",
      "best_move (25, 21)\n",
      "white moved 25, 21\n",
      "\n",
      "_b_b_b_b\n",
      "._b_._b_\n",
      "_._._b_b\n",
      "._b_._._\n",
      "_._._._.\n",
      "w_w_w_._\n",
      "_._._w_w\n",
      "w_w_w_w_\n",
      "11 turn: black last_moved_piece: None\n",
      "10 legal moves [(0, 4), (1, 6), (2, 6), (5, 8), (5, 9), (10, 14), (10, 15), (11, 15), (13, 16), (13, 17)]\n",
      "legal_move [(0, 4), (1, 6), (2, 6), (5, 8), (5, 9), (10, 14), (10, 15), (11, 15), (13, 16), (13, 17)]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 34\u001b[0m\n\u001b[0;32m     30\u001b[0m white_player \u001b[38;5;241m=\u001b[39m MinimaxPlayer(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwhite\u001b[39m\u001b[38;5;124m'\u001b[39m, value_func\u001b[38;5;241m=\u001b[39mpartial(material_value_adv, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwhite\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m), search_depth\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m, seed\u001b[38;5;241m=\u001b[39mi \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m     31\u001b[0m \u001b[38;5;66;03m# white_player = RandomPlayer('white', seed=i * 2)\u001b[39;00m\n\u001b[0;32m     32\u001b[0m \n\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m#modify this function to put our RL model as white\u001b[39;00m\n\u001b[1;32m---> 34\u001b[0m winner \u001b[38;5;241m=\u001b[39m \u001b[43mplay_a_game\u001b[49m\u001b[43m(\u001b[49m\u001b[43mch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mblack_player\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnext_move\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwhite_player\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnext_move\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_game_len\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;66;03m# Play with a minimax player\u001b[39;00m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;66;03m# play_a_game(ch, keyboard_player_move, white_player.next_move)\u001b[39;00m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mblack player evaluated \u001b[39m\u001b[38;5;132;01m%i\u001b[39;00m\u001b[38;5;124m positions in \u001b[39m\u001b[38;5;132;01m%.2f\u001b[39;00m\u001b[38;5;124ms (avg \u001b[39m\u001b[38;5;132;01m%.2f\u001b[39;00m\u001b[38;5;124m positions/s) effective branching factor \u001b[39m\u001b[38;5;132;01m%.2f\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m (black_player\u001b[38;5;241m.\u001b[39mn_evaluated_positions, black_player\u001b[38;5;241m.\u001b[39mevaluation_dt, black_player\u001b[38;5;241m.\u001b[39mn_evaluated_positions \u001b[38;5;241m/\u001b[39m black_player\u001b[38;5;241m.\u001b[39mevaluation_dt, (black_player\u001b[38;5;241m.\u001b[39mn_evaluated_positions \u001b[38;5;241m/\u001b[39m black_player\u001b[38;5;241m.\u001b[39mply) \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m/\u001b[39m black_player\u001b[38;5;241m.\u001b[39msearch_depth)))\n",
      "File \u001b[1;32mc:\\Users\\pream\\Documents\\project_2024\\pattern recog\\term_project\\pattern_term_project_2024\\gym-checkers\\checkers\\agents\\baselines.py:51\u001b[0m, in \u001b[0;36mplay_a_game\u001b[1;34m(checkers, black_player_move, white_player_move, max_plies)\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%i\u001b[39;00m\u001b[38;5;124m legal moves \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m (\u001b[38;5;28mlen\u001b[39m(moves), moves))\n\u001b[0;32m     50\u001b[0m \u001b[38;5;66;03m# Select a legal move for the current player\u001b[39;00m\n\u001b[1;32m---> 51\u001b[0m from_sq, to_sq \u001b[38;5;241m=\u001b[39m \u001b[43mplayers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mturn\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mboard\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlast_moved_piece\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28mprint\u001b[39m(turn, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmoved \u001b[39m\u001b[38;5;132;01m%i\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m%i\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m (from_sq, to_sq))\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28mprint\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\pream\\Documents\\project_2024\\pattern recog\\term_project\\pattern_term_project_2024\\gym-checkers\\checkers\\agents\\alpha_beta.py:76\u001b[0m, in \u001b[0;36mMinimaxPlayer.next_move\u001b[1;34m(self, board, last_moved_piece)\u001b[0m\n\u001b[0;32m     73\u001b[0m     best_move \u001b[38;5;241m=\u001b[39m moves[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     74\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     75\u001b[0m     \u001b[38;5;66;03m# More than one legal move\u001b[39;00m\n\u001b[1;32m---> 76\u001b[0m     value, best_move \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mminimax_search\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     77\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mMinimaxPlayer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mMinimaxPlayer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwin\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch_depth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mset\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     78\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     79\u001b[0m     \u001b[38;5;66;03m# print('move', move, 'value', value)\u001b[39;00m\n\u001b[0;32m     80\u001b[0m dt \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m t0\n",
      "File \u001b[1;32mc:\\Users\\pream\\Documents\\project_2024\\pattern recog\\term_project\\pattern_term_project_2024\\gym-checkers\\checkers\\agents\\alpha_beta.py:146\u001b[0m, in \u001b[0;36mMinimaxPlayer.minimax_search\u001b[1;34m(self, state, alpha, beta, depth, visited_states)\u001b[0m\n\u001b[0;32m    144\u001b[0m next_state \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msimulator\u001b[38;5;241m.\u001b[39msave_state()\n\u001b[0;32m    145\u001b[0m \u001b[38;5;66;03m# Evaluate the next position\u001b[39;00m\n\u001b[1;32m--> 146\u001b[0m value, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mminimax_search\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    147\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnext_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    148\u001b[0m \u001b[43m    \u001b[49m\u001b[43mextreme_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    149\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbeta\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    150\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdepth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdepth\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    151\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvisited_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvisited_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    152\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    153\u001b[0m \u001b[38;5;66;03m# Update the max value\u001b[39;00m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m extreme_value \u001b[38;5;241m<\u001b[39m value:\n",
      "File \u001b[1;32mc:\\Users\\pream\\Documents\\project_2024\\pattern recog\\term_project\\pattern_term_project_2024\\gym-checkers\\checkers\\agents\\alpha_beta.py:173\u001b[0m, in \u001b[0;36mMinimaxPlayer.minimax_search\u001b[1;34m(self, state, alpha, beta, depth, visited_states)\u001b[0m\n\u001b[0;32m    171\u001b[0m next_state \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msimulator\u001b[38;5;241m.\u001b[39msave_state()\n\u001b[0;32m    172\u001b[0m \u001b[38;5;66;03m# Evaluate the next position\u001b[39;00m\n\u001b[1;32m--> 173\u001b[0m value, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mminimax_search\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    174\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnext_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    175\u001b[0m \u001b[43m    \u001b[49m\u001b[43malpha\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    176\u001b[0m \u001b[43m    \u001b[49m\u001b[43mextreme_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    177\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdepth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdepth\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    178\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvisited_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvisited_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    179\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    180\u001b[0m \u001b[38;5;66;03m# Update the min value\u001b[39;00m\n\u001b[0;32m    181\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m value \u001b[38;5;241m<\u001b[39m extreme_value:\n",
      "File \u001b[1;32mc:\\Users\\pream\\Documents\\project_2024\\pattern recog\\term_project\\pattern_term_project_2024\\gym-checkers\\checkers\\agents\\alpha_beta.py:146\u001b[0m, in \u001b[0;36mMinimaxPlayer.minimax_search\u001b[1;34m(self, state, alpha, beta, depth, visited_states)\u001b[0m\n\u001b[0;32m    144\u001b[0m next_state \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msimulator\u001b[38;5;241m.\u001b[39msave_state()\n\u001b[0;32m    145\u001b[0m \u001b[38;5;66;03m# Evaluate the next position\u001b[39;00m\n\u001b[1;32m--> 146\u001b[0m value, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mminimax_search\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    147\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnext_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    148\u001b[0m \u001b[43m    \u001b[49m\u001b[43mextreme_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    149\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbeta\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    150\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdepth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdepth\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    151\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvisited_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvisited_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    152\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    153\u001b[0m \u001b[38;5;66;03m# Update the max value\u001b[39;00m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m extreme_value \u001b[38;5;241m<\u001b[39m value:\n",
      "File \u001b[1;32mc:\\Users\\pream\\Documents\\project_2024\\pattern recog\\term_project\\pattern_term_project_2024\\gym-checkers\\checkers\\agents\\alpha_beta.py:173\u001b[0m, in \u001b[0;36mMinimaxPlayer.minimax_search\u001b[1;34m(self, state, alpha, beta, depth, visited_states)\u001b[0m\n\u001b[0;32m    171\u001b[0m next_state \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msimulator\u001b[38;5;241m.\u001b[39msave_state()\n\u001b[0;32m    172\u001b[0m \u001b[38;5;66;03m# Evaluate the next position\u001b[39;00m\n\u001b[1;32m--> 173\u001b[0m value, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mminimax_search\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    174\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnext_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    175\u001b[0m \u001b[43m    \u001b[49m\u001b[43malpha\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    176\u001b[0m \u001b[43m    \u001b[49m\u001b[43mextreme_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    177\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdepth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdepth\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    178\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvisited_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvisited_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    179\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    180\u001b[0m \u001b[38;5;66;03m# Update the min value\u001b[39;00m\n\u001b[0;32m    181\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m value \u001b[38;5;241m<\u001b[39m extreme_value:\n",
      "File \u001b[1;32mc:\\Users\\pream\\Documents\\project_2024\\pattern recog\\term_project\\pattern_term_project_2024\\gym-checkers\\checkers\\agents\\alpha_beta.py:146\u001b[0m, in \u001b[0;36mMinimaxPlayer.minimax_search\u001b[1;34m(self, state, alpha, beta, depth, visited_states)\u001b[0m\n\u001b[0;32m    144\u001b[0m next_state \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msimulator\u001b[38;5;241m.\u001b[39msave_state()\n\u001b[0;32m    145\u001b[0m \u001b[38;5;66;03m# Evaluate the next position\u001b[39;00m\n\u001b[1;32m--> 146\u001b[0m value, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mminimax_search\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    147\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnext_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    148\u001b[0m \u001b[43m    \u001b[49m\u001b[43mextreme_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    149\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbeta\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    150\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdepth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdepth\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    151\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvisited_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvisited_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    152\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    153\u001b[0m \u001b[38;5;66;03m# Update the max value\u001b[39;00m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m extreme_value \u001b[38;5;241m<\u001b[39m value:\n",
      "File \u001b[1;32mc:\\Users\\pream\\Documents\\project_2024\\pattern recog\\term_project\\pattern_term_project_2024\\gym-checkers\\checkers\\agents\\alpha_beta.py:173\u001b[0m, in \u001b[0;36mMinimaxPlayer.minimax_search\u001b[1;34m(self, state, alpha, beta, depth, visited_states)\u001b[0m\n\u001b[0;32m    171\u001b[0m next_state \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msimulator\u001b[38;5;241m.\u001b[39msave_state()\n\u001b[0;32m    172\u001b[0m \u001b[38;5;66;03m# Evaluate the next position\u001b[39;00m\n\u001b[1;32m--> 173\u001b[0m value, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mminimax_search\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    174\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnext_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    175\u001b[0m \u001b[43m    \u001b[49m\u001b[43malpha\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    176\u001b[0m \u001b[43m    \u001b[49m\u001b[43mextreme_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    177\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdepth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdepth\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    178\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvisited_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvisited_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    179\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    180\u001b[0m \u001b[38;5;66;03m# Update the min value\u001b[39;00m\n\u001b[0;32m    181\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m value \u001b[38;5;241m<\u001b[39m extreme_value:\n",
      "File \u001b[1;32mc:\\Users\\pream\\Documents\\project_2024\\pattern recog\\term_project\\pattern_term_project_2024\\gym-checkers\\checkers\\agents\\alpha_beta.py:112\u001b[0m, in \u001b[0;36mMinimaxPlayer.minimax_search\u001b[1;34m(self, state, alpha, beta, depth, visited_states)\u001b[0m\n\u001b[0;32m    109\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcached_values[im_state]\n\u001b[0;32m    111\u001b[0m \u001b[38;5;66;03m# Evaluate this state\u001b[39;00m\n\u001b[1;32m--> 112\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msimulator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrestore_state\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    113\u001b[0m moves \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msimulator\u001b[38;5;241m.\u001b[39mlegal_moves()\n\u001b[0;32m    114\u001b[0m \u001b[38;5;66;03m# Base case. Win/loss check\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\pream\\Documents\\project_2024\\pattern recog\\term_project\\pattern_term_project_2024\\gym-checkers\\checkers\\game.py:367\u001b[0m, in \u001b[0;36mCheckers.restore_state\u001b[1;34m(self, state)\u001b[0m\n\u001b[0;32m    365\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrestore_state\u001b[39m(\u001b[38;5;28mself\u001b[39m, state):\n\u001b[0;32m    366\u001b[0m     board, turn, last_moved_piece \u001b[38;5;241m=\u001b[39m state\n\u001b[1;32m--> 367\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_board \u001b[38;5;241m=\u001b[39m \u001b[43mcopy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mboard\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    368\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_turn \u001b[38;5;241m=\u001b[39m turn\n\u001b[0;32m    369\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_last_moved_piece \u001b[38;5;241m=\u001b[39m last_moved_piece\n",
      "File \u001b[1;32mc:\\Users\\pream\\miniconda3\\envs\\pattern_checker\\lib\\copy.py:146\u001b[0m, in \u001b[0;36mdeepcopy\u001b[1;34m(x, memo, _nil)\u001b[0m\n\u001b[0;32m    144\u001b[0m copier \u001b[38;5;241m=\u001b[39m _deepcopy_dispatch\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;28mcls\u001b[39m)\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copier \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 146\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43mcopier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    147\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    148\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;28mtype\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\pream\\miniconda3\\envs\\pattern_checker\\lib\\copy.py:230\u001b[0m, in \u001b[0;36m_deepcopy_dict\u001b[1;34m(x, memo, deepcopy)\u001b[0m\n\u001b[0;32m    228\u001b[0m memo[\u001b[38;5;28mid\u001b[39m(x)] \u001b[38;5;241m=\u001b[39m y\n\u001b[0;32m    229\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m x\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m--> 230\u001b[0m     y[\u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m] \u001b[38;5;241m=\u001b[39m deepcopy(value, memo)\n\u001b[0;32m    231\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m y\n",
      "File \u001b[1;32mc:\\Users\\pream\\miniconda3\\envs\\pattern_checker\\lib\\copy.py:146\u001b[0m, in \u001b[0;36mdeepcopy\u001b[1;34m(x, memo, _nil)\u001b[0m\n\u001b[0;32m    144\u001b[0m copier \u001b[38;5;241m=\u001b[39m _deepcopy_dispatch\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;28mcls\u001b[39m)\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copier \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 146\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43mcopier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    147\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    148\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;28mtype\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\pream\\miniconda3\\envs\\pattern_checker\\lib\\copy.py:182\u001b[0m, in \u001b[0;36m_deepcopy_atomic\u001b[1;34m(x, memo)\u001b[0m\n\u001b[0;32m    178\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m y\n\u001b[0;32m    180\u001b[0m _deepcopy_dispatch \u001b[38;5;241m=\u001b[39m d \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m--> 182\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_deepcopy_atomic\u001b[39m(x, memo):\n\u001b[0;32m    183\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n\u001b[0;32m    184\u001b[0m d[\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28;01mNone\u001b[39;00m)] \u001b[38;5;241m=\u001b[39m _deepcopy_atomic\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from checkers.agents.baselines import play_a_game, RandomPlayer\n",
    "from checkers.game import Checkers\n",
    "from checkers.agents import Player\n",
    "from checkers.agents.alpha_beta import MinimaxPlayer, first_order_adv, material_value_adv\n",
    "from functools import partial\n",
    "\n",
    "# A few matches against a random player\n",
    "max_game_len = 500\n",
    "n_matches = 1\n",
    "n_wins, n_draws, n_losses = 0, 0, 0\n",
    "for i in range(n_matches):\n",
    "    print('game', i)\n",
    "    ch = Checkers()\n",
    "    black_player = MinimaxPlayer(\n",
    "        'black',\n",
    "        value_func=partial(first_order_adv, 'black', 200, 100, 20, 0),\n",
    "        # The provided legal moves might be ordered differently\n",
    "        rollout_order_gen=lambda x: sorted(x),\n",
    "        search_depth=6,\n",
    "        seed=i)\n",
    "    \n",
    "    white_player = MinimaxPlayer(\n",
    "        'white',\n",
    "        value_func=partial(first_order_adv, 'White', 200, 100, 20, 0),\n",
    "        # The provided legal moves might be ordered differently\n",
    "        rollout_order_gen=lambda x: sorted(x),\n",
    "        search_depth=6,\n",
    "        seed=i)\n",
    "\n",
    "    white_player = MinimaxPlayer('white', value_func=partial(material_value_adv, 'white', 2, 1), search_depth=4, seed=i * 2)\n",
    "    # white_player = RandomPlayer('white', seed=i * 2)\n",
    "\n",
    "    #modify this function to put our RL model as white\n",
    "    winner = play_a_game(ch, black_player.next_move, white_player.next_move, max_game_len)\n",
    "\n",
    "    # Play with a minimax player\n",
    "    # play_a_game(ch, keyboard_player_move, white_player.next_move)\n",
    "\n",
    "    print('black player evaluated %i positions in %.2fs (avg %.2f positions/s) effective branching factor %.2f' % (black_player.n_evaluated_positions, black_player.evaluation_dt, black_player.n_evaluated_positions / black_player.evaluation_dt, (black_player.n_evaluated_positions / black_player.ply) ** (1 / black_player.search_depth)))\n",
    "    print('black player pruned', black_player.prunes.items())\n",
    "    print()\n",
    "    # Keep scores\n",
    "    n_wins += 1 if winner == 'black' else 0\n",
    "    n_draws += 1 if winner is None else 0\n",
    "    n_losses += 1 if winner == 'white' else 0\n",
    "\n",
    "print('black win', n_wins, 'draw', n_draws, 'loss', n_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Gc0zdruy6Gqs"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
