{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xgDpm0Op6nRD"
   },
   "source": [
    "**Add gym-checkers to path**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "pwd = Path(os.getcwd())\n",
    "if (pwd.name == \"notebooks\"):\n",
    "    sys.path.append(str(pwd.parent / \"gym-checkers\"))\n",
    "else:\n",
    "    sys.path.append(str(pwd / \"gym-checkers\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g5JqySpj6cvd"
   },
   "source": [
    "**Quick test alpha-beta agent**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from checkers.game import Checkers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QzrYKxu35GpM",
    "outputId": "88359440-16bc-4a3a-c1ff-9113713f07b2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "game 0\n",
      "_b_b_b_b\n",
      "b_b_b_b_\n",
      "_b_b_b_b\n",
      "._._._._\n",
      "_._._._.\n",
      "w_w_w_w_\n",
      "_w_w_w_w\n",
      "w_w_w_w_\n",
      "0 turn: black last_moved_piece: None\n",
      "7 legal moves [(8, 12), (8, 13), (9, 13), (9, 14), (10, 14), (10, 15), (11, 15)]\n",
      "evaluated 1437 positions in 0.33s (avg 4318.84 positions/s) with effective branching factor 6.16\n",
      "black moved 8, 12\n",
      "\n",
      "_b_b_b_b\n",
      "b_b_b_b_\n",
      "_._b_b_b\n",
      "b_._._._\n",
      "_._._._.\n",
      "w_w_w_w_\n",
      "_w_w_w_w\n",
      "w_w_w_w_\n",
      "1 turn: white last_moved_piece: None\n",
      "7 legal moves [(20, 16), (21, 17), (21, 16), (22, 18), (22, 17), (23, 19), (23, 18)]\n",
      "evaluated 1312 positions in 0.39s (avg 3332.13 positions/s) with effective branching factor 6.02\n",
      "white moved 23, 18\n",
      "\n",
      "_b_b_b_b\n",
      "b_b_b_b_\n",
      "_._b_b_b\n",
      "b_._._._\n",
      "_._._w_.\n",
      "w_w_w_._\n",
      "_w_w_w_w\n",
      "w_w_w_w_\n",
      "2 turn: black last_moved_piece: None\n",
      "8 legal moves [(4, 8), (5, 8), (9, 13), (9, 14), (10, 14), (10, 15), (11, 15), (12, 16)]\n",
      "evaluated 660 positions in 0.16s (avg 4111.54 positions/s) with effective branching factor 5.07\n",
      "black moved 9, 14\n",
      "\n",
      "_b_b_b_b\n",
      "b_b_b_b_\n",
      "_._._b_b\n",
      "b_._b_._\n",
      "_._._w_.\n",
      "w_w_w_._\n",
      "_w_w_w_w\n",
      "w_w_w_w_\n",
      "3 turn: white last_moved_piece: None\n",
      "1 legal moves [(18, 9)]\n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "float division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 26\u001b[0m\n\u001b[0;32m     22\u001b[0m white_player \u001b[38;5;241m=\u001b[39m MinimaxPlayer(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwhite\u001b[39m\u001b[38;5;124m'\u001b[39m, value_func\u001b[38;5;241m=\u001b[39mpartial(material_value_adv, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwhite\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m), search_depth\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m, seed\u001b[38;5;241m=\u001b[39mi \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# white_player = RandomPlayer('white', seed=i * 2)\u001b[39;00m\n\u001b[0;32m     24\u001b[0m \n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m#modify this function to put our RL model as white\u001b[39;00m\n\u001b[1;32m---> 26\u001b[0m winner \u001b[38;5;241m=\u001b[39m \u001b[43mplay_a_game\u001b[49m\u001b[43m(\u001b[49m\u001b[43mch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mblack_player\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnext_move\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwhite_player\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnext_move\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_game_len\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# Play with a minimax player\u001b[39;00m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m# play_a_game(ch, keyboard_player_move, white_player.next_move)\u001b[39;00m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mblack player evaluated \u001b[39m\u001b[38;5;132;01m%i\u001b[39;00m\u001b[38;5;124m positions in \u001b[39m\u001b[38;5;132;01m%.2f\u001b[39;00m\u001b[38;5;124ms (avg \u001b[39m\u001b[38;5;132;01m%.2f\u001b[39;00m\u001b[38;5;124m positions/s) effective branching factor \u001b[39m\u001b[38;5;132;01m%.2f\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m (black_player\u001b[38;5;241m.\u001b[39mn_evaluated_positions, black_player\u001b[38;5;241m.\u001b[39mevaluation_dt, black_player\u001b[38;5;241m.\u001b[39mn_evaluated_positions \u001b[38;5;241m/\u001b[39m black_player\u001b[38;5;241m.\u001b[39mevaluation_dt, (black_player\u001b[38;5;241m.\u001b[39mn_evaluated_positions \u001b[38;5;241m/\u001b[39m black_player\u001b[38;5;241m.\u001b[39mply) \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m/\u001b[39m black_player\u001b[38;5;241m.\u001b[39msearch_depth)))\n",
      "File \u001b[1;32mc:\\Users\\pream\\Documents\\project_2024\\pattern recog\\term_project\\pattern_term_project_2024\\gym-checkers\\checkers\\agents\\baselines.py:51\u001b[0m, in \u001b[0;36mplay_a_game\u001b[1;34m(checkers, black_player_move, white_player_move, max_plies)\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%i\u001b[39;00m\u001b[38;5;124m legal moves \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m (\u001b[38;5;28mlen\u001b[39m(moves), moves))\n\u001b[0;32m     50\u001b[0m \u001b[38;5;66;03m# Select a legal move for the current player\u001b[39;00m\n\u001b[1;32m---> 51\u001b[0m from_sq, to_sq \u001b[38;5;241m=\u001b[39m \u001b[43mplayers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mturn\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mboard\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlast_moved_piece\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28mprint\u001b[39m(turn, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmoved \u001b[39m\u001b[38;5;132;01m%i\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m%i\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m (from_sq, to_sq))\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28mprint\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\pream\\Documents\\project_2024\\pattern recog\\term_project\\pattern_term_project_2024\\gym-checkers\\checkers\\agents\\alpha_beta.py:69\u001b[0m, in \u001b[0;36mMinimaxPlayer.next_move\u001b[1;34m(self, board, last_moved_piece)\u001b[0m\n\u001b[0;32m     67\u001b[0m dt \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m t0\n\u001b[0;32m     68\u001b[0m dm \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_evaluated_positions \u001b[38;5;241m-\u001b[39m m0\n\u001b[1;32m---> 69\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mevaluated \u001b[39m\u001b[38;5;132;01m%i\u001b[39;00m\u001b[38;5;124m positions in \u001b[39m\u001b[38;5;132;01m%.2f\u001b[39;00m\u001b[38;5;124ms (avg \u001b[39m\u001b[38;5;132;01m%.2f\u001b[39;00m\u001b[38;5;124m positions/s) with effective branching factor \u001b[39m\u001b[38;5;132;01m%.2f\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m (dm, dt, \u001b[43mdm\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdt\u001b[49m, dm \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msearch_depth)))\n\u001b[0;32m     70\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluation_dt \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m dt\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mply \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[1;31mZeroDivisionError\u001b[0m: float division by zero"
     ]
    }
   ],
   "source": [
    "from checkers.agents.baselines import play_a_game, RandomPlayer\n",
    "from checkers.game import Checkers\n",
    "from checkers.agents import Player\n",
    "from checkers.agents.alpha_beta import MinimaxPlayer, first_order_adv, material_value_adv\n",
    "from functools import partial\n",
    "\n",
    "# A few matches against a random player\n",
    "max_game_len = 200\n",
    "n_matches = 1\n",
    "n_wins, n_draws, n_losses = 0, 0, 0\n",
    "for i in range(n_matches):\n",
    "    print('game', i)\n",
    "    ch = Checkers()\n",
    "    black_player = MinimaxPlayer(\n",
    "        'black',\n",
    "        value_func=partial(first_order_adv, 'black', 200, 100, 20, 0),\n",
    "        # The provided legal moves might be ordered differently\n",
    "        rollout_order_gen=lambda x: sorted(x),\n",
    "        search_depth=4,\n",
    "        seed=i)\n",
    "\n",
    "    white_player = MinimaxPlayer('white', value_func=partial(material_value_adv, 'white', 2, 1), search_depth=4, seed=i * 2)\n",
    "    # white_player = RandomPlayer('white', seed=i * 2)\n",
    "\n",
    "    #modify this function to put our RL model as white\n",
    "    winner = play_a_game(ch, black_player.next_move, white_player.next_move, max_game_len)\n",
    "\n",
    "    # Play with a minimax player\n",
    "    # play_a_game(ch, keyboard_player_move, white_player.next_move)\n",
    "\n",
    "    print('black player evaluated %i positions in %.2fs (avg %.2f positions/s) effective branching factor %.2f' % (black_player.n_evaluated_positions, black_player.evaluation_dt, black_player.n_evaluated_positions / black_player.evaluation_dt, (black_player.n_evaluated_positions / black_player.ply) ** (1 / black_player.search_depth)))\n",
    "    print('black player pruned', black_player.prunes.items())\n",
    "    print()\n",
    "    # Keep scores\n",
    "    n_wins += 1 if winner == 'black' else 0\n",
    "    n_draws += 1 if winner is None else 0\n",
    "    n_losses += 1 if winner == 'white' else 0\n",
    "\n",
    "print('black win', n_wins, 'draw', n_draws, 'loss', n_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Gc0zdruy6Gqs"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
